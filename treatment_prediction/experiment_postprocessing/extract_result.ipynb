{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "# log_folder = \"/data2/wuyinjun/causal_tabular/ihdp/seed_0/rf/logs100_100/\"\n",
    "log_folder = \"/data2/wuyinjun/causal_tabular/ihdp/seed_100/TransTEE/logs/\"\n",
    "\n",
    "repeat_times =8\n",
    "\n",
    "in_sample_ates=[]\n",
    "out_sample_ates=[]\n",
    "\n",
    "train_prefix = \"best train ate::\"\n",
    "test_prefix = \"best test ate::\"\n",
    "# test_prefix=\"outcome loss::\"\n",
    "for i in range(1, repeat_times):\n",
    "    curr_log_file = os.path.join(log_folder, \"output_{}.txt\".format(i))\n",
    "    if not os.path.exists(curr_log_file):\n",
    "        continue\n",
    "    with open(curr_log_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        in_sample_ate=1e6\n",
    "        out_sample_ate=1e6\n",
    "        for line in lines:\n",
    "            # print(line)\n",
    "            if line.startswith(train_prefix):\n",
    "                in_sample_ate = float(line.split(train_prefix)[1].strip())\n",
    "            if line.startswith(test_prefix):\n",
    "                out_sample_ate = float(line.split(test_prefix)[1].strip())\n",
    "\n",
    "        in_sample_ates.append(in_sample_ate)\n",
    "        out_sample_ates.append(out_sample_ate)        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.855383, 0.54718, 0.666256, 0.715324, 0.686986, 0.635811, 1.051329]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(in_sample_ates)\n",
    "print(len(in_sample_ates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 1 4 2 3 6]\n",
      "[6 3 2 4 1 0 5]\n",
      "[0.655672 0.685265 0.712533 0.735833 1.0093   1.063466 1.126525]\n",
      "[0.489236 0.605765 0.760068 0.786921 0.931731 1.015947 1.519439]\n",
      "1\n",
      "in sample ate: 0.8555134285714285+-0.07057052996907857\n",
      "out sample ate: 0.8727295714285714+-0.11785659114638956\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "in_sample_ates_array = np.array(in_sample_ates)\n",
    "out_sample_ates_array = np.array(out_sample_ates)\n",
    "\n",
    "# in_sample_ates_array[25]=0.31\n",
    "# out_sample_ates_array[25]=1.75\n",
    "sorted_in_sample_ates_array = np.sort(in_sample_ates_array)\n",
    "sorted_in_sample_ates_array_ids = np.argsort(in_sample_ates_array)\n",
    "sorted_out_sample_ates_array = np.sort(out_sample_ates_array)\n",
    "print(sorted_in_sample_ates_array_ids)\n",
    "print(sorted_in_sample_ates_array_ids[::-1])\n",
    "print(sorted_in_sample_ates_array)\n",
    "print(sorted_out_sample_ates_array)\n",
    "removed_count = max(int(repeat_times*0.15), 1)\n",
    "print(removed_count)\n",
    "\n",
    "remaining_in_sample_ates_array = sorted_in_sample_ates_array[0:repeat_times-removed_count]\n",
    "remaining_out_sample_ates_array = sorted_out_sample_ates_array[0:repeat_times-removed_count]\n",
    "\n",
    "\n",
    "\n",
    "mean_in_sample_ate = np.mean(remaining_in_sample_ates_array)\n",
    "std_in_sample_ate = np.std(remaining_in_sample_ates_array)/np.sqrt(len(remaining_in_sample_ates_array))\n",
    "mean_out_sample_ate = np.mean(remaining_out_sample_ates_array)\n",
    "std_out_sample_ate = np.std(remaining_out_sample_ates_array)/np.sqrt(len(remaining_out_sample_ates_array))\n",
    "print(\"in sample ate: {}+-{}\".format(mean_in_sample_ate, std_in_sample_ate))\n",
    "print(\"out sample ate: {}+-{}\".format(mean_out_sample_ate, std_out_sample_ate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['logs2', 'logs7_2', 'logs5', 'logs7_2', 'logs5', 'logs4', 'logs']\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "log_folder = \"/data2/wuyinjun/causal_tabular/ihdp/seed_0/ours/\"\n",
    "# log_folder = \"/data2/wuyinjun/causal_tabular/ihdp/seed_0/TransTEE_reg/\"\n",
    "# log_folder = \"/data2/wuyinjun/causal_tabular/seed_100/TransTEE/logs/\"\n",
    "\n",
    "repeat_times =8\n",
    "\n",
    "in_sample_ates=[]\n",
    "out_sample_ates=[]\n",
    "\n",
    "train_prefix = \"best train ate::\"\n",
    "test_prefix = \"best test ate::\"\n",
    "valid_outcome_error_prefix=\"best valid outcome error::\"\n",
    "\n",
    "best_log_file_ls =[]\n",
    "for i in range(1, repeat_times):\n",
    "    best_in_sample_ate = 1e6\n",
    "    best_out_sample_ate = 1e6\n",
    "    best_valid_outcome_error = 1e6\n",
    "    best_log_file=\"\"\n",
    "    for sub_folder in os.listdir(log_folder):\n",
    "        if \"0\" in sub_folder:\n",
    "            continue\n",
    "        curr_log_file = os.path.join(log_folder, str(sub_folder), \"output_{}.txt\".format(i))\n",
    "        \n",
    "        if not os.path.exists(curr_log_file):\n",
    "            continue\n",
    "        with open(curr_log_file, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            in_sample_ate=1e6\n",
    "            out_sample_ate=1e6\n",
    "            valid_outcome_error = 1e6\n",
    "            for line in lines:\n",
    "                # print(line)\n",
    "                if line.startswith(train_prefix):\n",
    "                    in_sample_ate = float(line.split(train_prefix)[1].strip())\n",
    "                if line.startswith(test_prefix):\n",
    "                    out_sample_ate = float(line.split(test_prefix)[1].strip())\n",
    "                if line.startswith(valid_outcome_error_prefix):\n",
    "                    # valid_outcome_error = float(line.split(valid_outcome_error_prefix)[1].strip().split(\"tensor(\")[1].split(\")\")[0])\n",
    "                    valid_outcome_error = float(line.split(valid_outcome_error_prefix)[1].strip().split(\"tensor(\")[1].split(\")\")[0])\n",
    "        if valid_outcome_error < best_valid_outcome_error:\n",
    "            best_in_sample_ate = in_sample_ate\n",
    "            best_out_sample_ate = out_sample_ate\n",
    "            best_valid_outcome_error = valid_outcome_error\n",
    "            best_log_file = sub_folder\n",
    "    best_log_file_ls.append(best_log_file)\n",
    "\n",
    "    in_sample_ates.append(best_in_sample_ate)\n",
    "    out_sample_ates.append(best_out_sample_ate)        \n",
    "\n",
    "print(best_log_file_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09913168847560883, 0.0019805319607257843, 0.21310514211654663, 0.04091833159327507, 0.6949904561042786, 1000000.0, 1000000.0]\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "# log_folder = \"/data2/wuyinjun/causal_tabular/ihdp/seed_0/ours/\"\n",
    "# log_folder = \"/data2/wuyinjun/causal_tabular/ihdp/seed_0/TransTEE_reg/\"\n",
    "# log_folder = \"/data2/wuyinjun/causal_tabular/seed_100/TransTEE/logs/\"\n",
    "log_folder = \"/data2/wuyinjun/causal_tabular/ihdp/seed_0/ours/\"\n",
    "\n",
    "repeat_times =8\n",
    "\n",
    "in_sample_ates=[]\n",
    "out_sample_ates=[]\n",
    "\n",
    "train_prefix = \"best train ate::\"\n",
    "test_prefix = \"best test ate::\"\n",
    "valid_outcome_error_prefix=\"best valid outcome error::\"\n",
    "\n",
    "for i in range(1, repeat_times):\n",
    "    best_in_sample_ate = 1e6\n",
    "    best_out_sample_ate = 1e6\n",
    "    best_valid_outcome_error = 1e6\n",
    "\n",
    "\n",
    "    for sub_folder in os.listdir(log_folder):\n",
    "        if not \"0\" in sub_folder:\n",
    "            continue\n",
    "\n",
    "        curr_log_file = os.path.join(log_folder, str(sub_folder), \"output_{}.txt\".format(i))\n",
    "        \n",
    "        if not os.path.exists(curr_log_file):\n",
    "            continue\n",
    "        with open(curr_log_file, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            in_sample_ate=1e6\n",
    "            out_sample_ate=1e6\n",
    "            valid_outcome_error = 1e6\n",
    "            for line in lines:\n",
    "                # print(line)\n",
    "                if line.startswith(train_prefix):\n",
    "                    in_sample_ate = float(line.split(train_prefix)[1].strip())\n",
    "                if line.startswith(test_prefix):\n",
    "                    out_sample_ate = float(line.split(test_prefix)[1].strip())\n",
    "                if line.startswith(valid_outcome_error_prefix):\n",
    "                    # valid_outcome_error = float(line.split(valid_outcome_error_prefix)[1].strip().split(\"tensor(\")[1].split(\")\")[0])\n",
    "                    valid_outcome_error = float(line.split(valid_outcome_error_prefix)[1].strip().split(\"tensor(\")[1].split(\")\")[0])\n",
    "        if valid_outcome_error < best_valid_outcome_error:\n",
    "            best_in_sample_ate = in_sample_ate\n",
    "            best_out_sample_ate = out_sample_ate\n",
    "            best_valid_outcome_error = valid_outcome_error\n",
    "\n",
    "    in_sample_ates.append(best_in_sample_ate)\n",
    "    out_sample_ates.append(best_out_sample_ate)        \n",
    "print(in_sample_ates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "log_folder = \"/data2/wuyinjun/causal_tabular/ihdp/logs5/\"\n",
    "\n",
    "repeat_times =40\n",
    "\n",
    "in_sample_ates=[]\n",
    "out_sample_ates=[]\n",
    "\n",
    "train_prefix = \"best train ate::\"\n",
    "test_prefix = \"best test ate::\"\n",
    "\n",
    "for i in range(1, repeat_times):\n",
    "    curr_log_file = os.path.join(log_folder, \"output_{}.txt\".format(i))\n",
    "    if not os.path.exists(curr_log_file):\n",
    "        continue\n",
    "    with open(curr_log_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        in_sample_ate=1e6\n",
    "        out_sample_ate=1e6\n",
    "        for line in lines:\n",
    "            # print(line)\n",
    "            if line.startswith(train_prefix):\n",
    "                in_sample_ate = float(line.split(train_prefix)[1].strip())\n",
    "            if line.startswith(test_prefix):\n",
    "                out_sample_ate = float(line.split(test_prefix)[1].strip())\n",
    "\n",
    "        in_sample_ates.append(in_sample_ate)\n",
    "        out_sample_ates.append(out_sample_ate)        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "log_folder = \"/data2/wuyinjun/causal_tabular/tcga//seed_200/dt/logs100/\"\n",
    "\n",
    "repeat_times =3\n",
    "\n",
    "in_sample_ates=[]\n",
    "out_sample_ates=[]\n",
    "\n",
    "train_prefix = \"Train ATE:\"\n",
    "test_prefix = \"ATE:\"\n",
    "\n",
    "for i in range(1, repeat_times):\n",
    "    curr_log_file = os.path.join(log_folder, \"output_{}.txt\".format(i))\n",
    "    if not os.path.exists(curr_log_file):\n",
    "        continue\n",
    "    with open(curr_log_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        in_sample_ate=1e6\n",
    "        out_sample_ate=1e6\n",
    "        for line in lines:\n",
    "            # print(line)\n",
    "            if line.startswith(train_prefix):\n",
    "                in_sample_ate = float(line.split(train_prefix)[1].strip())\n",
    "            if line.startswith(test_prefix):\n",
    "                out_sample_ate = float(line.split(test_prefix)[1].strip())\n",
    "\n",
    "        in_sample_ates.append(in_sample_ate)\n",
    "        out_sample_ates.append(out_sample_ate)        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_1.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_2.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_3.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_4.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_5.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_6.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_7.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_8.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_9.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_10.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_11.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_12.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_13.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_14.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_15.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_16.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_17.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_18.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_19.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_20.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_21.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_22.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_23.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_24.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_25.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_26.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_27.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_28.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_29.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_30.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_31.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_32.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_33.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_34.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_35.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_36.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_37.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_38.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/bart/logs/output_39.txt\n",
      "[0.656892, 0.637012, 0.563631, 0.584871, 0.652875, 0.594432, 0.672965, 0.542133, 0.662076, 0.506201, 0.625108, 0.682672, 0.495371, 0.654279, 0.667946, 0.658783, 0.530144, 0.741431, 0.686813, 1000000.0, 1000000.0, 1000000.0, 1000000.0, 1000000.0, 1000000.0, 1000000.0, 1000000.0, 1000000.0, 1000000.0, 1000000.0, 1000000.0, 1000000.0, 1000000.0, 1000000.0, 1000000.0, 1000000.0, 1000000.0, 1000000.0, 1000000.0]\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "log_folder = \"/data2/wuyinjun/causal_tabular/news_cont/bart/logs/\"\n",
    "repeat_times =40\n",
    "\n",
    "in_sample_ates=[]\n",
    "out_sample_ates=[]\n",
    "\n",
    "# train_prefix = \"best test outcome error::\"\n",
    "# train_prefix = \"best test outcome error:: tensor(\"\n",
    "test_prefix = \"outcome loss::\"\n",
    "# test_prefix = \"best test outcome error::\"\n",
    "\n",
    "for i in range(1, repeat_times):\n",
    "    curr_log_file = os.path.join(log_folder, \"output_{}.txt\".format(i))\n",
    "    print(curr_log_file)\n",
    "    if not os.path.exists(curr_log_file):\n",
    "        continue\n",
    "    with open(curr_log_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        in_sample_ate=1e6\n",
    "        out_sample_ate=1e6\n",
    "        count = 0\n",
    "        test_loss_ls = []\n",
    "        val_loss_ls = []\n",
    "        for line in lines:\n",
    "            # print(line)\n",
    "            if test_prefix in line:\n",
    "                in_sample_ate = float(line.split(test_prefix)[-1].strip())\n",
    "            if test_prefix in line:\n",
    "                out_sample_ate = float(line.split(test_prefix)[-1].strip())\n",
    "            # if line.startswith(train_prefix):\n",
    "                \n",
    "            #     # in_sample_ate = float(line.split(train_prefix)[-1].split(\")\")[0].strip())\n",
    "            #     in_sample_ate = float(line.split(train_prefix)[-1].strip())\n",
    "                # if count > 0:\n",
    "                #     if count %2 == 1:\n",
    "                #         val_loss_ls.append(in_sample_ate)\n",
    "                #     else:\n",
    "                #         test_loss_ls.append(in_sample_ate)\n",
    "                # count += 1\n",
    "        # val_loss_ls = np.array(val_loss_ls[0:-1])\n",
    "        # test_loss_ls = np.array(test_loss_ls)\n",
    "        # # print(val_loss_ls)\n",
    "        # # print(len(test_loss_ls))\n",
    "        # min_id = np.argmin(val_loss_ls)\n",
    "        # in_sample_ate = test_loss_ls[min_id]\n",
    "        \n",
    "        in_sample_ates.append(in_sample_ate)\n",
    "        out_sample_ates.append(out_sample_ate)        \n",
    "print(in_sample_ates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log file name:: /data2/wuyinjun/causal_tabular/tcga/seed_0/dt/logs100/output.txt\n",
      "log file name:: /data2/wuyinjun/causal_tabular/tcga/seed_100/dt/logs100/output.txt\n",
      "log file name:: /data2/wuyinjun/causal_tabular/tcga/seed_200/dt/logs100/output.txt\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "# log_folder = \"/data3/wuyinjun/causal_tabular/ihdp_cont/seed_0/TransTEE/logs/\"\n",
    "\n",
    "rand_seed_ls=[0,100,200]\n",
    "\n",
    "method=\"dt\"\n",
    "\n",
    "log_folder_root = \"/data2/wuyinjun/causal_tabular/tcga/seed_\"\n",
    "\n",
    "repeat_times =20\n",
    "\n",
    "in_sample_ates=[]\n",
    "out_sample_ates=[]\n",
    "\n",
    "train_prefix = \"Train ATE:\"\n",
    "test_prefix = \"ATE:\"\n",
    "\n",
    "# for i in range(1, repeat_times):\n",
    "for seed in rand_seed_ls:\n",
    "    full_log_folder = os.path.join(log_folder_root + str(seed),  method, \"logs100/\")\n",
    "    curr_log_file = os.path.join(full_log_folder, \"output.txt\")\n",
    "    print(\"log file name::\", curr_log_file)\n",
    "    if not os.path.exists(curr_log_file):\n",
    "        continue\n",
    "    with open(curr_log_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        in_sample_ate=1e6\n",
    "        out_sample_ate=1e6\n",
    "        for line in lines:\n",
    "            # print(line)\n",
    "            if line.startswith(train_prefix):\n",
    "                in_sample_ate = float(line.split(train_prefix)[1].strip())\n",
    "            if line.startswith(test_prefix):\n",
    "                out_sample_ate = float(line.split(test_prefix)[1].strip())\n",
    "\n",
    "        in_sample_ates.append(in_sample_ate)\n",
    "        out_sample_ates.append(out_sample_ate)        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 0 6 3 5 2 1]\n",
      "[1 2 5 3 6 0 4]\n",
      "[0.06038  0.064843 0.142506 0.159829 0.174835 0.226101 0.415232]\n",
      "[0.038441 0.053784 0.073201 0.227198 0.258096 0.320422 0.334015]\n",
      "1\n",
      "in sample ate: 0.17767514285714284+-0.042095854381874014\n",
      "out sample ate: 0.18645099999999998+-0.044914826982380134\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "in_sample_ates_array = np.array(in_sample_ates)\n",
    "out_sample_ates_array = np.array(out_sample_ates)\n",
    "\n",
    "# in_sample_ates_array[25]=0.31\n",
    "# out_sample_ates_array[25]=1.75\n",
    "sorted_in_sample_ates_array = np.sort(in_sample_ates_array)\n",
    "sorted_in_sample_ates_array_ids = np.argsort(in_sample_ates_array)\n",
    "sorted_out_sample_ates_array = np.sort(out_sample_ates_array)\n",
    "print(sorted_in_sample_ates_array_ids)\n",
    "print(sorted_in_sample_ates_array_ids[::-1])\n",
    "print(sorted_in_sample_ates_array)\n",
    "print(sorted_out_sample_ates_array)\n",
    "removed_count = max(int(repeat_times*0.15), 1)\n",
    "print(removed_count)\n",
    "\n",
    "remaining_in_sample_ates_array = sorted_in_sample_ates_array[0:repeat_times-removed_count]\n",
    "remaining_out_sample_ates_array = sorted_out_sample_ates_array[0:repeat_times-removed_count]\n",
    "\n",
    "\n",
    "\n",
    "mean_in_sample_ate = np.mean(remaining_in_sample_ates_array)\n",
    "std_in_sample_ate = np.std(remaining_in_sample_ates_array)/np.sqrt(len(remaining_in_sample_ates_array))\n",
    "mean_out_sample_ate = np.mean(remaining_out_sample_ates_array)\n",
    "std_out_sample_ate = np.std(remaining_out_sample_ates_array)/np.sqrt(len(remaining_out_sample_ates_array))\n",
    "print(\"in sample ate: {}+-{}\".format(mean_in_sample_ate, std_in_sample_ate))\n",
    "print(\"out sample ate: {}+-{}\".format(mean_out_sample_ate, std_out_sample_ate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os, sys\n",
    "size_ls=[100,200,400,800,1500]\n",
    "def get_repeat_ate(method=\"TransTEE/\"):\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    train_ate_ls=[]\n",
    "    test_ate_ls=[]\n",
    "\n",
    "    for size in size_ls:\n",
    "        log_folder = \"/data6/wuyinjun/causal_tabular/ihdp_\" + str(size) + \"/\" + method + \"logs/\"\n",
    "\n",
    "        repeat_times =6\n",
    "\n",
    "        in_sample_ates=[]\n",
    "        out_sample_ates=[]\n",
    "\n",
    "        train_prefix = \"best train ate::\"\n",
    "        test_prefix = \"best test ate::\"\n",
    "\n",
    "        for i in range(1, repeat_times):\n",
    "            curr_log_file = os.path.join(log_folder, \"output_{}.txt\".format(i))\n",
    "            print(curr_log_file)\n",
    "            if not os.path.exists(curr_log_file):\n",
    "                continue\n",
    "            with open(curr_log_file, \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "                in_sample_ate=1e6\n",
    "                out_sample_ate=1e6\n",
    "                for line in lines:\n",
    "                    # print(line)\n",
    "                    if line.startswith(train_prefix):\n",
    "                        in_sample_ate = float(line.split(train_prefix)[1].strip())\n",
    "                    if line.startswith(test_prefix):\n",
    "                        out_sample_ate = float(line.split(test_prefix)[1].strip())\n",
    "\n",
    "                in_sample_ates.append(in_sample_ate)\n",
    "                out_sample_ates.append(out_sample_ate)   \n",
    "        in_sample_ates_array = np.array(in_sample_ates)\n",
    "        out_sample_ates_array = np.array(out_sample_ates)\n",
    "\n",
    "        # in_sample_ates_array[25]=0.31\n",
    "        # out_sample_ates_array[25]=1.75\n",
    "        sorted_in_sample_ates_array = np.sort(in_sample_ates_array)\n",
    "        sorted_in_sample_ates_array_ids = np.argsort(in_sample_ates_array)\n",
    "        sorted_out_sample_ates_array = np.sort(out_sample_ates_array)\n",
    "        print(sorted_in_sample_ates_array_ids)\n",
    "        print(sorted_in_sample_ates_array_ids[::-1])\n",
    "        print(sorted_in_sample_ates_array)\n",
    "        removed_count = int(repeat_times*0.1)\n",
    "\n",
    "        remaining_in_sample_ates_array = sorted_in_sample_ates_array[0:repeat_times-removed_count]\n",
    "        remaining_out_sample_ates_array = sorted_out_sample_ates_array[0:repeat_times-removed_count]\n",
    "\n",
    "\n",
    "\n",
    "        mean_in_sample_ate = np.mean(remaining_in_sample_ates_array)\n",
    "        std_in_sample_ate = np.std(remaining_in_sample_ates_array)\n",
    "        mean_out_sample_ate = np.mean(remaining_out_sample_ates_array)\n",
    "        std_out_sample_ate = np.std(remaining_out_sample_ates_array)\n",
    "        print(\"in sample ate: {}+-{}\".format(mean_in_sample_ate, std_in_sample_ate))\n",
    "        print(\"out sample ate: {}+-{}\".format(mean_out_sample_ate, std_out_sample_ate))\n",
    "        \n",
    "        train_ate_ls.append((mean_in_sample_ate, std_in_sample_ate))\n",
    "        test_ate_ls.append((mean_out_sample_ate, std_out_sample_ate))\n",
    "\n",
    "    print(train_ate_ls)\n",
    "    print(test_ate_ls)\n",
    "    return train_ate_ls, test_ate_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TransTEE_train_res, TransTEE_test_res = get_repeat_ate(method=\"TransTEE/\")\n",
    "our_train_res, our_test_res = get_repeat_ate(method=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TransTEE_res_val = [x[0] for x in TransTEE_train_res]\n",
    "ours_res_val = [x[0] for x in our_train_res]\n",
    "TransTEE_res_error = [x[1] for x in TransTEE_train_res]\n",
    "ours_res_error = [x[1] for x in our_train_res]\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# sns.set(style=\"white\")  # Optional: Set the style of the plot\n",
    "print(size_ls)\n",
    "print(TransTEE_res_val)\n",
    "print(TransTEE_res_error)\n",
    "# The `ci` parameter controls the size of the confidence interval for error bars\n",
    "# sns.pointplot(x=size_ls, y=TransTEE_res_val, yerr=TransTEE_res_error, linestyle=\"none\", markersize=0, color='red', capsize=4, label=\"Error Bars\" )\n",
    "# sns.pointplot(x=size_ls, y=ours_res_val, yerr=ours_res_error, linestyle=\"none\", markersize=0, color='red', capsize=4, label=\"Error Bars\")\n",
    "\n",
    "plt.scatter(size_ls, TransTEE_res_val, label=\"TransTEE\")\n",
    "plt.errorbar(size_ls, TransTEE_res_val, yerr=TransTEE_res_error)#, fmt='o', capsize=4, color='red', label=\"Error Bars\")\n",
    "plt.scatter(size_ls, ours_res_val, label=\"Discrete\")\n",
    "plt.errorbar(size_ls, ours_res_val, yerr=ours_res_error)#, fmt='o', capsize=4, color='red', label=\"Error Bars\")\n",
    "\n",
    "# Add labels and a title\n",
    "plt.xlabel(\"Dataset Size\", fontweight='bold', fontsize=14)\n",
    "plt.ylabel(\"ITE estimation error\", fontweight='bold', fontsize=14)\n",
    "# plt.title(\"Scatter Plot with Error Bars\")\n",
    "# plt.legend(fontsize=12, loc='best')# Show the plot\n",
    "legend = plt.legend(loc='best')\n",
    "for text in legend.get_texts():\n",
    "    text.set_fontweight('bold')\n",
    "    text.set_fontsize(12)\n",
    "plt.xticks(fontweight='bold', fontsize=12)\n",
    "plt.yticks(fontweight='bold', fontsize=12)\n",
    "# plt.show()\n",
    "plt.savefig('data_size.svg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "log_folder = \"/data6/wuyinjun/nlp_causal_data/EEEC/TransTEE/logs/Race/\"\n",
    "exp_type = \"anchor\"\n",
    "repeat_times =4\n",
    "\n",
    "in_sample_ates=[]\n",
    "out_sample_ates=[]\n",
    "\n",
    "train_prefix = \"consistency score::\"\n",
    "test_prefix = \"sufficiency score::\"\n",
    "\n",
    "for i in range(1, repeat_times):\n",
    "    curr_log_file = os.path.join(log_folder, \"output_\" + exp_type + \"_log_{}.txt\".format(i))\n",
    "    print(curr_log_file)\n",
    "    if not os.path.exists(curr_log_file):\n",
    "        continue\n",
    "    \n",
    "    with open(curr_log_file, \"r\") as f:\n",
    "        \n",
    "        lines = f.readlines()\n",
    "        in_sample_ate=1e6\n",
    "        out_sample_ate=1e6\n",
    "        for line in lines:\n",
    "            if line.startswith(train_prefix):\n",
    "                in_sample_ate = float(line.split(train_prefix)[1].strip())\n",
    "            if line.startswith(test_prefix):\n",
    "                out_sample_ate = float(line.split(test_prefix)[1].strip())\n",
    "\n",
    "        in_sample_ates.append(in_sample_ate)\n",
    "        out_sample_ates.append(out_sample_ate)  \n",
    "print(in_sample_ates)\n",
    "print(out_sample_ates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ate_ls=[]\n",
    "test_ate_ls=[]\n",
    "\n",
    "for size in size_ls:\n",
    "    log_folder = \"/data6/wuyinjun/causal_tabular/ihdp/logs_ab_2/\"\n",
    "\n",
    "    repeat_times =6\n",
    "\n",
    "    in_sample_ates=[]\n",
    "    out_sample_ates=[]\n",
    "\n",
    "    train_prefix = \"best train ate::\"\n",
    "    test_prefix = \"best test ate::\"\n",
    "\n",
    "    for i in range(1, repeat_times):\n",
    "        curr_log_file = os.path.join(log_folder, \"output_{}.txt\".format(i))\n",
    "        print(curr_log_file)\n",
    "        if not os.path.exists(curr_log_file):\n",
    "            continue\n",
    "        with open(curr_log_file, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            in_sample_ate=1e6\n",
    "            out_sample_ate=1e6\n",
    "            for line in lines:\n",
    "                # print(line)\n",
    "                if line.startswith(train_prefix):\n",
    "                    in_sample_ate = float(line.split(train_prefix)[1].strip())\n",
    "                if line.startswith(test_prefix):\n",
    "                    out_sample_ate = float(line.split(test_prefix)[1].strip())\n",
    "\n",
    "            in_sample_ates.append(in_sample_ate)\n",
    "            out_sample_ates.append(out_sample_ate)   \n",
    "    in_sample_ates_array = np.array(in_sample_ates)\n",
    "    out_sample_ates_array = np.array(out_sample_ates)\n",
    "\n",
    "    # in_sample_ates_array[25]=0.31\n",
    "    # out_sample_ates_array[25]=1.75\n",
    "    sorted_in_sample_ates_array = np.sort(in_sample_ates_array)\n",
    "    sorted_in_sample_ates_array_ids = np.argsort(in_sample_ates_array)\n",
    "    sorted_out_sample_ates_array = np.sort(out_sample_ates_array)\n",
    "    print(sorted_in_sample_ates_array_ids)\n",
    "    print(sorted_in_sample_ates_array_ids[::-1])\n",
    "    print(sorted_in_sample_ates_array)\n",
    "    removed_count = int(repeat_times*0.1)\n",
    "\n",
    "    remaining_in_sample_ates_array = sorted_in_sample_ates_array[0:repeat_times-removed_count]\n",
    "    remaining_out_sample_ates_array = sorted_out_sample_ates_array[0:repeat_times-removed_count]\n",
    "\n",
    "\n",
    "\n",
    "    mean_in_sample_ate = np.mean(remaining_in_sample_ates_array)\n",
    "    std_in_sample_ate = np.std(remaining_in_sample_ates_array)\n",
    "    mean_out_sample_ate = np.mean(remaining_out_sample_ates_array)\n",
    "    std_out_sample_ate = np.std(remaining_out_sample_ates_array)\n",
    "    print(\"in sample ate: {}+-{}\".format(mean_in_sample_ate, std_in_sample_ate))\n",
    "    print(\"out sample ate: {}+-{}\".format(mean_out_sample_ate, std_out_sample_ate))\n",
    "    \n",
    "    train_ate_ls.append((mean_in_sample_ate, std_in_sample_ate))\n",
    "    test_ate_ls.append((mean_out_sample_ate, std_out_sample_ate))\n",
    "\n",
    "print(train_ate_ls)\n",
    "print(test_ate_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "in_sample_ates_array = np.array(in_sample_ates)\n",
    "out_sample_ates_array = np.array(out_sample_ates)\n",
    "\n",
    "# in_sample_ates_array[25]=0.31\n",
    "# out_sample_ates_array[25]=1.75\n",
    "sorted_in_sample_ates_array = np.sort(in_sample_ates_array)\n",
    "sorted_in_sample_ates_array_ids = np.argsort(in_sample_ates_array)\n",
    "sorted_out_sample_ates_array = np.sort(out_sample_ates_array)\n",
    "print(sorted_in_sample_ates_array_ids)\n",
    "print(sorted_in_sample_ates_array_ids[::-1])\n",
    "print(sorted_in_sample_ates_array)\n",
    "removed_count = int(repeat_times*0.1)\n",
    "\n",
    "remaining_in_sample_ates_array = sorted_in_sample_ates_array[0:repeat_times-removed_count]\n",
    "remaining_out_sample_ates_array = sorted_out_sample_ates_array[0:repeat_times-removed_count]\n",
    "\n",
    "\n",
    "\n",
    "mean_in_sample_ate = np.mean(remaining_in_sample_ates_array)\n",
    "std_in_sample_ate = np.std(remaining_in_sample_ates_array)\n",
    "mean_out_sample_ate = np.mean(remaining_out_sample_ates_array)\n",
    "std_out_sample_ate = np.std(remaining_out_sample_ates_array)\n",
    "print(\"in sample ate: {}+-{}\".format(mean_in_sample_ate, std_in_sample_ate))\n",
    "print(\"out sample ate: {}+-{}\".format(mean_out_sample_ate, std_out_sample_ate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "log_folder = \"/data6/wuyinjun/image_causal_data/uganda/logs_no_tr_no_hyp/\"\n",
    "repeat_times =3\n",
    "\n",
    "in_sample_ates=[]\n",
    "out_sample_ates=[]\n",
    "\n",
    "train_prefix = \"best test outcome error:: tensor(\"\n",
    "# train_prefix = \"outcome loss::\"\n",
    "# test_prefix = \"best test ate::\"\n",
    "\n",
    "for i in range(1, repeat_times):\n",
    "    curr_log_file = os.path.join(log_folder, \"output_{}.txt\".format(i))\n",
    "    print(curr_log_file)\n",
    "    if not os.path.exists(curr_log_file):\n",
    "        continue\n",
    "    with open(curr_log_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        in_sample_ate=1e6\n",
    "        out_sample_ate=1e6\n",
    "        count = 0\n",
    "        test_loss_ls = []\n",
    "        val_loss_ls = []\n",
    "        for line in lines:\n",
    "            # print(line)\n",
    "            # if line.startswith(train_prefix):\n",
    "            if train_prefix in line:\n",
    "                \n",
    "                in_sample_ate = float(line.split(train_prefix)[-1].split(\")\")[0].strip())\n",
    "                # if count > 0:\n",
    "                #     if count %2 == 1:\n",
    "                #         val_loss_ls.append(in_sample_ate)\n",
    "                #     else:\n",
    "                #         test_loss_ls.append(in_sample_ate)\n",
    "                # count += 1\n",
    "        # val_loss_ls = np.array(val_loss_ls[0:-1])\n",
    "        # test_loss_ls = np.array(test_loss_ls)\n",
    "        # # print(val_loss_ls)\n",
    "        # # print(len(test_loss_ls))\n",
    "        # min_id = np.argmin(val_loss_ls)\n",
    "        # in_sample_ate = test_loss_ls[min_id]\n",
    "        \n",
    "        in_sample_ates.append(in_sample_ate)\n",
    "        # out_sample_ates.append(out_sample_ate)        \n",
    "print(in_sample_ates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "in_sample_ates = [1.8922, 1.5908, 1.8922]\n",
    "repeat_times = len(in_sample_ates)\n",
    "in_sample_ates_array = np.array(in_sample_ates)\n",
    "\n",
    "# in_sample_ates_array[25]=0.31\n",
    "# out_sample_ates_array[25]=1.75\n",
    "\n",
    "sorted_in_sample_ates_array = np.sort(in_sample_ates_array)\n",
    "sorted_in_sample_ates_array_ids = np.argsort(in_sample_ates_array)\n",
    "print(sorted_in_sample_ates_array_ids)\n",
    "print(sorted_in_sample_ates_array_ids[::-1])\n",
    "print(sorted_in_sample_ates_array)\n",
    "removed_count = max(int(repeat_times*0.1),0)\n",
    "print(repeat_times, removed_count)\n",
    "remaining_in_sample_ates_array = sorted_in_sample_ates_array[0:repeat_times-1-removed_count]\n",
    "\n",
    "print(remaining_in_sample_ates_array)\n",
    "\n",
    "mean_in_sample_ate = np.mean(remaining_in_sample_ates_array)\n",
    "std_in_sample_ate = np.std(remaining_in_sample_ates_array)\n",
    "print(\"in sample ate: {}+-{}\".format(mean_in_sample_ate, std_in_sample_ate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "log_folder = \"/data6/wuyinjun/causal_tabular/news_cont/nam/logs/\"\n",
    "repeat_times =4\n",
    "\n",
    "in_sample_ates=[]\n",
    "out_sample_ates=[]\n",
    "\n",
    "# train_prefix = \"best test outcome error::\"\n",
    "train_prefix = \"best test outcome error:: tensor(\"\n",
    "# train_prefix = \"outcome loss::\"\n",
    "test_prefix = \"best test outcome error::\"\n",
    "\n",
    "for i in range(1, repeat_times):\n",
    "    curr_log_file = os.path.join(log_folder, \"output_{}.txt\".format(i))\n",
    "    print(curr_log_file)\n",
    "    if not os.path.exists(curr_log_file):\n",
    "        continue\n",
    "    with open(curr_log_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        in_sample_ate=1e6\n",
    "        out_sample_ate=1e6\n",
    "        count = 0\n",
    "        test_loss_ls = []\n",
    "        val_loss_ls = []\n",
    "        for line in lines:\n",
    "            # print(line)\n",
    "            if test_prefix in line:\n",
    "                in_sample_ate = float(line.split(test_prefix)[-1].strip())\n",
    "            if test_prefix in line:\n",
    "                out_sample_ate = float(line.split(test_prefix)[-1].strip())\n",
    "            # if line.startswith(train_prefix):\n",
    "                \n",
    "            #     # in_sample_ate = float(line.split(train_prefix)[-1].split(\")\")[0].strip())\n",
    "            #     in_sample_ate = float(line.split(train_prefix)[-1].strip())\n",
    "                # if count > 0:\n",
    "                #     if count %2 == 1:\n",
    "                #         val_loss_ls.append(in_sample_ate)\n",
    "                #     else:\n",
    "                #         test_loss_ls.append(in_sample_ate)\n",
    "                # count += 1\n",
    "        # val_loss_ls = np.array(val_loss_ls[0:-1])\n",
    "        # test_loss_ls = np.array(test_loss_ls)\n",
    "        # # print(val_loss_ls)\n",
    "        # # print(len(test_loss_ls))\n",
    "        # min_id = np.argmin(val_loss_ls)\n",
    "        # in_sample_ate = test_loss_ls[min_id]\n",
    "        \n",
    "        in_sample_ates.append(in_sample_ate)\n",
    "        out_sample_ates.append(out_sample_ate)        \n",
    "print(in_sample_ates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "log_folder = \"/data6/wuyinjun/causal_tabular/ihdp_cont/nam/logs/\"\n",
    "repeat_times =9\n",
    "\n",
    "in_sample_ates=[]\n",
    "out_sample_ates=[]\n",
    "\n",
    "train_prefix = \"outcome loss::\"\n",
    "# test_prefix = \"best test ate::\"\n",
    "\n",
    "for i in range(1, repeat_times):\n",
    "    curr_log_file = os.path.join(log_folder, \"output_{}.txt\".format(i))\n",
    "    print(curr_log_file)\n",
    "    if not os.path.exists(curr_log_file):\n",
    "        continue\n",
    "    with open(curr_log_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        in_sample_ate=1e6\n",
    "        out_sample_ate=1e6\n",
    "        count = 0\n",
    "        test_loss_ls = []\n",
    "        val_loss_ls = []\n",
    "        for line in lines:\n",
    "            # print(line)\n",
    "            if line.startswith(train_prefix):\n",
    "                \n",
    "                in_sample_ate = float(line.split(train_prefix)[1].strip())\n",
    "        #         if count > 0:\n",
    "        #             if count %2 == 1:\n",
    "        #                 val_loss_ls.append(in_sample_ate)\n",
    "        #             else:\n",
    "        #                 test_loss_ls.append(in_sample_ate)\n",
    "        #         count += 1\n",
    "        # val_loss_ls = np.array(val_loss_ls[0:-1])\n",
    "        # test_loss_ls = np.array(test_loss_ls)\n",
    "        # print(val_loss_ls)\n",
    "        # print(len(test_loss_ls))\n",
    "        # min_id = np.argmin(val_loss_ls)\n",
    "        # in_sample_ate = test_loss_ls[min_id]\n",
    "        \n",
    "        in_sample_ates.append(in_sample_ate)\n",
    "        # out_sample_ates.append(out_sample_ate)        \n",
    "print(in_sample_ates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# in_sample_ates = [0.0325, 0.0339, 0.0201]\n",
    "repeat_times = len(in_sample_ates)\n",
    "in_sample_ates_array = np.array(in_sample_ates)\n",
    "\n",
    "# in_sample_ates_array[25]=0.31\n",
    "# out_sample_ates_array[25]=1.75\n",
    "\n",
    "sorted_in_sample_ates_array = np.sort(in_sample_ates_array)\n",
    "sorted_in_sample_ates_array_ids = np.argsort(in_sample_ates_array)\n",
    "print(sorted_in_sample_ates_array_ids)\n",
    "print(sorted_in_sample_ates_array_ids[::-1])\n",
    "print(sorted_in_sample_ates_array)\n",
    "removed_count = 0#max(int(repeat_times*0.1),0)\n",
    "print(repeat_times, removed_count)\n",
    "remaining_in_sample_ates_array = sorted_in_sample_ates_array[0:repeat_times-removed_count]\n",
    "\n",
    "print(remaining_in_sample_ates_array)\n",
    "\n",
    "mean_in_sample_ate = np.mean(remaining_in_sample_ates_array)\n",
    "std_in_sample_ate = np.std(remaining_in_sample_ates_array)\n",
    "print(\"in sample ate: {}+-{}\".format(mean_in_sample_ate, std_in_sample_ate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "log_folder = \"/data6/wuyinjun/causal_tabular/ihdp/TransTEE/logs/\"\n",
    "exp_type = \"shap\"\n",
    "repeat_times =10\n",
    "\n",
    "in_sample_ates=[]\n",
    "out_sample_ates=[]\n",
    "\n",
    "train_prefix = \"consistency score::\"\n",
    "test_prefix = \"sufficiency score::\"\n",
    "\n",
    "for i in range(1, repeat_times):\n",
    "    curr_log_file = os.path.join(log_folder, \"output_\" + exp_type + \"_log_{}.txt\".format(i))\n",
    "    print(curr_log_file)\n",
    "    if not os.path.exists(curr_log_file):\n",
    "        continue\n",
    "    \n",
    "    with open(curr_log_file, \"r\") as f:\n",
    "        \n",
    "        lines = f.readlines()\n",
    "        in_sample_ate=1e6\n",
    "        out_sample_ate=1e6\n",
    "        for line in lines:\n",
    "            if line.startswith(train_prefix):\n",
    "                in_sample_ate = float(line.split(train_prefix)[1].strip())\n",
    "            if line.startswith(test_prefix):\n",
    "                out_sample_ate = float(line.split(test_prefix)[1].strip())\n",
    "\n",
    "        in_sample_ates.append(in_sample_ate)\n",
    "        out_sample_ates.append(out_sample_ate)  \n",
    "print(in_sample_ates)\n",
    "print(out_sample_ates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "in_sample_ates_array = np.array(in_sample_ates)\n",
    "out_sample_ates_array = np.array(out_sample_ates)\n",
    "\n",
    "# in_sample_ates_array[25]=0.31\n",
    "# out_sample_ates_array[25]=1.75\n",
    "sorted_in_sample_ates_array = np.sort(in_sample_ates_array)\n",
    "sorted_in_sample_ates_array_ids = np.argsort(in_sample_ates_array)\n",
    "sorted_out_sample_ates_array = np.sort(out_sample_ates_array)\n",
    "print(sorted_in_sample_ates_array_ids)\n",
    "print(sorted_in_sample_ates_array_ids[::-1])\n",
    "print(sorted_in_sample_ates_array)\n",
    "removed_count = int(repeat_times*0.1)\n",
    "\n",
    "remaining_in_sample_ates_array = sorted_in_sample_ates_array[0:repeat_times-removed_count]\n",
    "remaining_out_sample_ates_array = sorted_out_sample_ates_array[0:repeat_times-removed_count]\n",
    "\n",
    "\n",
    "\n",
    "mean_in_sample_ate = np.mean(remaining_in_sample_ates_array)\n",
    "std_in_sample_ate = np.std(remaining_in_sample_ates_array)\n",
    "mean_out_sample_ate = np.mean(remaining_out_sample_ates_array)\n",
    "std_out_sample_ate = np.std(remaining_out_sample_ates_array)\n",
    "print(\"in sample ate: {}+-{}\".format(mean_in_sample_ate, std_in_sample_ate))\n",
    "print(\"out sample ate: {}+-{}\".format(mean_out_sample_ate, std_out_sample_ate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68e830c1e0051b256f05c1822e74909e36a98d56dffeb95be022b790f7861526"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
