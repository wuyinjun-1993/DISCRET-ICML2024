{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "log_folder = \"/data2/wuyinjun/causal_tabular/ihdp/seed_0/TransTEE/logs/\"\n",
    "# log_folder = \"/data2/wuyinjun/causal_tabular/seed_100/TransTEE/logs/\"\n",
    "\n",
    "repeat_times =40\n",
    "\n",
    "in_sample_ates=[]\n",
    "out_sample_ates=[]\n",
    "\n",
    "train_prefix = \"best train ate::\"\n",
    "test_prefix = \"best test ate::\"\n",
    "\n",
    "for i in range(1, repeat_times):\n",
    "    curr_log_file = os.path.join(log_folder, \"output_{}.txt\".format(i))\n",
    "    if not os.path.exists(curr_log_file):\n",
    "        continue\n",
    "    with open(curr_log_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        in_sample_ate=1e6\n",
    "        out_sample_ate=1e6\n",
    "        for line in lines:\n",
    "            # print(line)\n",
    "            if line.startswith(train_prefix):\n",
    "                in_sample_ate = float(line.split(train_prefix)[1].strip())\n",
    "            if line.startswith(test_prefix):\n",
    "                out_sample_ate = float(line.split(test_prefix)[1].strip())\n",
    "\n",
    "        in_sample_ates.append(in_sample_ate)\n",
    "        out_sample_ates.append(out_sample_ate)        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11964251101016998, 0.14476360380649567, 0.07203982770442963, 0.0861506462097168, 0.1133354902267456, 0.13789591193199158, 0.06664419919252396, 0.09967854619026184, 0.43495312333106995, 0.03435023874044418, 0.021999895572662354, 0.0681886076927185, 0.049955226480960846, 0.026489749550819397, 0.18426281213760376, 0.012650387361645699, 0.09779830276966095, 0.051412105560302734, 0.23473113775253296, 0.10735078155994415, 0.26664459705352783, 0.02881506085395813, 0.01563352718949318, 0.07789479196071625, 0.07530392706394196, 0.2928944230079651, 0.15995019674301147, 0.8788167238235474, 0.04130282625555992, 0.07160106301307678, 0.00835077278316021, 0.025827523320913315, 0.24220770597457886, 0.5574612021446228, 0.2010759711265564, 0.018753347918391228, 0.08975839614868164, 0.10531581193208694, 0.20385777950286865]\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "print(in_sample_ates)\n",
    "print(len(in_sample_ates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "log_folder = \"/data2/wuyinjun/causal_tabular/ihdp_cont/seed_0/ours/\"\n",
    "# log_folder = \"/data2/wuyinjun/causal_tabular/seed_100/TransTEE/logs/\"\n",
    "\n",
    "repeat_times =40\n",
    "\n",
    "in_sample_ates=[]\n",
    "out_sample_ates=[]\n",
    "\n",
    "train_prefix = \"best train ate::\"\n",
    "test_prefix = \"best test ate::\"\n",
    "valid_outcome_error_prefix=\"best valid outcome error::\"\n",
    "\n",
    "for i in range(1, repeat_times):\n",
    "    best_in_sample_ate = 1e6\n",
    "    best_out_sample_ate = 1e6\n",
    "    best_valid_outcome_error = 1e6\n",
    "    for sub_folder in os.listdir(log_folder):\n",
    "        curr_log_file = os.path.join(log_folder, str(sub_folder), \"output_{}.txt\".format(i))\n",
    "        \n",
    "        if not os.path.exists(curr_log_file):\n",
    "            continue\n",
    "        with open(curr_log_file, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            in_sample_ate=1e6\n",
    "            out_sample_ate=1e6\n",
    "            valid_outcome_error = 1e6\n",
    "            for line in lines:\n",
    "                # print(line)\n",
    "                if line.startswith(train_prefix):\n",
    "                    in_sample_ate = float(line.split(train_prefix)[1].strip())\n",
    "                if line.startswith(test_prefix):\n",
    "                    out_sample_ate = float(line.split(test_prefix)[1].strip())\n",
    "                if line.startswith(valid_outcome_error_prefix):\n",
    "                    valid_outcome_error = float(line.split(valid_outcome_error_prefix)[1].strip().split(\"tensor(\")[1].split(\")\")[0])\n",
    "        if valid_outcome_error < best_valid_outcome_error:\n",
    "            best_in_sample_ate = in_sample_ate\n",
    "            best_out_sample_ate = out_sample_ate\n",
    "            best_valid_outcome_error = valid_outcome_error\n",
    "\n",
    "    in_sample_ates.append(best_in_sample_ate)\n",
    "    out_sample_ates.append(best_out_sample_ate)        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "log_folder = \"/data2/wuyinjun/causal_tabular/ihdp/logs5/\"\n",
    "\n",
    "repeat_times =40\n",
    "\n",
    "in_sample_ates=[]\n",
    "out_sample_ates=[]\n",
    "\n",
    "train_prefix = \"best train ate::\"\n",
    "test_prefix = \"best test ate::\"\n",
    "\n",
    "for i in range(1, repeat_times):\n",
    "    curr_log_file = os.path.join(log_folder, \"output_{}.txt\".format(i))\n",
    "    if not os.path.exists(curr_log_file):\n",
    "        continue\n",
    "    with open(curr_log_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        in_sample_ate=1e6\n",
    "        out_sample_ate=1e6\n",
    "        for line in lines:\n",
    "            # print(line)\n",
    "            if line.startswith(train_prefix):\n",
    "                in_sample_ate = float(line.split(train_prefix)[1].strip())\n",
    "            if line.startswith(test_prefix):\n",
    "                out_sample_ate = float(line.split(test_prefix)[1].strip())\n",
    "\n",
    "        in_sample_ates.append(in_sample_ate)\n",
    "        out_sample_ates.append(out_sample_ate)        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "log_folder = \"/data2/wuyinjun/causal_tabular/tcga/causal_rf/logs/\"\n",
    "\n",
    "repeat_times =3\n",
    "\n",
    "in_sample_ates=[]\n",
    "out_sample_ates=[]\n",
    "\n",
    "train_prefix = \"Train PE:\"\n",
    "test_prefix = \"PE:\"\n",
    "\n",
    "for i in range(1, repeat_times):\n",
    "    curr_log_file = os.path.join(log_folder, \"output_{}.txt\".format(i))\n",
    "    if not os.path.exists(curr_log_file):\n",
    "        continue\n",
    "    with open(curr_log_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        in_sample_ate=1e6\n",
    "        out_sample_ate=1e6\n",
    "        for line in lines:\n",
    "            # print(line)\n",
    "            if line.startswith(train_prefix):\n",
    "                in_sample_ate = float(line.split(train_prefix)[1].strip())\n",
    "            if line.startswith(test_prefix):\n",
    "                out_sample_ate = float(line.split(test_prefix)[1].strip())\n",
    "\n",
    "        in_sample_ates.append(in_sample_ate)\n",
    "        out_sample_ates.append(out_sample_ate)        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data2/wuyinjun/causal_tabular/news_cont/seed_0/bart/logs/output_1.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/seed_0/bart/logs/output_2.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/seed_0/bart/logs/output_3.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/seed_0/bart/logs/output_4.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/seed_0/bart/logs/output_5.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/seed_0/bart/logs/output_6.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/seed_0/bart/logs/output_7.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/seed_0/bart/logs/output_8.txt\n",
      "/data2/wuyinjun/causal_tabular/news_cont/seed_0/bart/logs/output_9.txt\n",
      "[0.659199, 0.513213, 0.602463, 0.642568, 0.652202, 0.594967, 0.675039, 0.627476, 0.664145]\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "log_folder = \"/data2/wuyinjun/causal_tabular/news_cont/seed_0/bart/logs/\"\n",
    "repeat_times =10\n",
    "\n",
    "in_sample_ates=[]\n",
    "out_sample_ates=[]\n",
    "\n",
    "# train_prefix = \"best test outcome error::\"\n",
    "# train_prefix = \"best test outcome error:: tensor(\"\n",
    "test_prefix = \"outcome loss::\"\n",
    "# test_prefix = \"best test outcome error::\"\n",
    "\n",
    "for i in range(1, repeat_times):\n",
    "    curr_log_file = os.path.join(log_folder, \"output_{}.txt\".format(i))\n",
    "    print(curr_log_file)\n",
    "    if not os.path.exists(curr_log_file):\n",
    "        continue\n",
    "    with open(curr_log_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        in_sample_ate=1e6\n",
    "        out_sample_ate=1e6\n",
    "        count = 0\n",
    "        test_loss_ls = []\n",
    "        val_loss_ls = []\n",
    "        for line in lines:\n",
    "            # print(line)\n",
    "            if test_prefix in line:\n",
    "                in_sample_ate = float(line.split(test_prefix)[-1].strip())\n",
    "            if test_prefix in line:\n",
    "                out_sample_ate = float(line.split(test_prefix)[-1].strip())\n",
    "            # if line.startswith(train_prefix):\n",
    "                \n",
    "            #     # in_sample_ate = float(line.split(train_prefix)[-1].split(\")\")[0].strip())\n",
    "            #     in_sample_ate = float(line.split(train_prefix)[-1].strip())\n",
    "                # if count > 0:\n",
    "                #     if count %2 == 1:\n",
    "                #         val_loss_ls.append(in_sample_ate)\n",
    "                #     else:\n",
    "                #         test_loss_ls.append(in_sample_ate)\n",
    "                # count += 1\n",
    "        # val_loss_ls = np.array(val_loss_ls[0:-1])\n",
    "        # test_loss_ls = np.array(test_loss_ls)\n",
    "        # # print(val_loss_ls)\n",
    "        # # print(len(test_loss_ls))\n",
    "        # min_id = np.argmin(val_loss_ls)\n",
    "        # in_sample_ate = test_loss_ls[min_id]\n",
    "        \n",
    "        in_sample_ates.append(in_sample_ate)\n",
    "        out_sample_ates.append(out_sample_ate)        \n",
    "print(in_sample_ates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.079985, 0.059655, 0.027324, 0.026702, 0.013504, 0.025955, 0.044399, 0.038519, 0.085877, 0.020139, 0.072819, 0.022511, 0.054072, 0.032406, 0.066086, 0.04282, 0.053383, 0.111079, 0.048108]\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "log_folder = \"/data2/wuyinjun/causal_tabular/news_cont/seed_0/ours/\"\n",
    "# log_folder = \"/data2/wuyinjun/causal_tabular/seed_100/TransTEE/logs/\"\n",
    "\n",
    "repeat_times =20\n",
    "\n",
    "in_sample_ates=[]\n",
    "out_sample_ates=[]\n",
    "\n",
    "# train_prefix = \"best train ate::\"\n",
    "test_prefix = \"outcome loss::\"\n",
    "# valid_outcome_error_prefix=\"best valid outcome error::\"\n",
    "\n",
    "for i in range(1, repeat_times):\n",
    "    best_in_sample_ate = 1e6\n",
    "    best_out_sample_ate = 1e6\n",
    "    best_valid_outcome_error = 1e6\n",
    "    for sub_folder in os.listdir(log_folder):\n",
    "        curr_log_file = os.path.join(log_folder, str(sub_folder), \"output_{}.txt\".format(i))\n",
    "        \n",
    "        if not os.path.exists(curr_log_file):\n",
    "            continue\n",
    "        with open(curr_log_file, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            in_sample_ate=1e6\n",
    "            out_sample_ate=1e6\n",
    "            valid_outcome_error = 1e6\n",
    "            for line in lines:\n",
    "                # print(line)\n",
    "                # if line.startswith(train_prefix):\n",
    "                #     in_sample_ate = float(line.split(train_prefix)[1].strip())\n",
    "                if line.startswith(test_prefix):\n",
    "                    out_sample_ate = float(line.split(test_prefix)[1].strip())\n",
    "                # if line.startswith(valid_outcome_error_prefix):\n",
    "                #     valid_outcome_error = float(line.split(valid_outcome_error_prefix)[1].strip().split(\"tensor(\")[1].split(\")\")[0])\n",
    "        if out_sample_ate < best_out_sample_ate:\n",
    "            # best_in_sample_ate = in_sample_ate\n",
    "            best_out_sample_ate = out_sample_ate\n",
    "            # best_valid_outcome_error = valid_outcome_error\n",
    "\n",
    "    # in_sample_ates.append(best_in_sample_ate)\n",
    "    out_sample_ates.append(best_out_sample_ate)        \n",
    "\n",
    "print(out_sample_ates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.892161, 0.331277, 0.272294, 0.30728, 0.314809, 0.308165, 0.421674, 1.059586, 0.379826, 0.420254, 0.27254, 0.297139, 0.75797, 0.377125, 0.279978, 0.295986, 0.281036, 1.353699, 0.304679]\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "log_folder = \"/data2/wuyinjun/causal_tabular/news_cont/seed_0/TransTEE_reg/\"\n",
    "# log_folder = \"/data2/wuyinjun/causal_tabular/seed_100/TransTEE/logs/\"\n",
    "\n",
    "repeat_times =20\n",
    "\n",
    "in_sample_ates=[]\n",
    "out_sample_ates=[]\n",
    "\n",
    "# train_prefix = \"best train ate::\"\n",
    "test_prefix = \"outcome loss::\"\n",
    "# valid_outcome_error_prefix=\"best valid outcome error::\"\n",
    "\n",
    "for i in range(1, repeat_times):\n",
    "    best_in_sample_ate = 1e6\n",
    "    best_out_sample_ate = 1e6\n",
    "    best_valid_outcome_error = 1e6\n",
    "    for sub_folder in os.listdir(log_folder):\n",
    "        curr_log_file = os.path.join(log_folder, str(sub_folder), \"output_{}.txt\".format(i))\n",
    "        \n",
    "        if not os.path.exists(curr_log_file):\n",
    "            continue\n",
    "        with open(curr_log_file, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            in_sample_ate=1e6\n",
    "            out_sample_ate=1e6\n",
    "            valid_outcome_error = 1e6\n",
    "            for line in lines:\n",
    "                # print(line)\n",
    "                # if line.startswith(train_prefix):\n",
    "                #     in_sample_ate = float(line.split(train_prefix)[1].strip())\n",
    "                if line.startswith(test_prefix):\n",
    "                    out_sample_ate = float(line.split(test_prefix)[1].strip())\n",
    "                # if line.startswith(valid_outcome_error_prefix):\n",
    "                #     valid_outcome_error = float(line.split(valid_outcome_error_prefix)[1].strip().split(\"tensor(\")[1].split(\")\")[0])\n",
    "        if out_sample_ate < best_out_sample_ate:\n",
    "            # best_in_sample_ate = in_sample_ate\n",
    "            best_out_sample_ate = out_sample_ate\n",
    "            # best_valid_outcome_error = valid_outcome_error\n",
    "\n",
    "    # in_sample_ates.append(best_in_sample_ate)\n",
    "    out_sample_ates.append(best_out_sample_ate)        \n",
    "\n",
    "print(out_sample_ates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.272294 0.27254  0.279978 0.281036 0.295986 0.297139 0.304679 0.30728\n",
      " 0.308165 0.314809 0.331277 0.377125 0.379826 0.420254 0.421674 0.75797\n",
      " 0.892161 1.059586 1.353699]\n",
      "3\n",
      "in sample ate: nan+-nan\n",
      "out sample ate: 0.3831878235294118+-0.04109147433451771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wuyinjun/anaconda3/envs/myenv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/wuyinjun/anaconda3/envs/myenv/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/wuyinjun/anaconda3/envs/myenv/lib/python3.10/site-packages/numpy/core/_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/wuyinjun/anaconda3/envs/myenv/lib/python3.10/site-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/wuyinjun/anaconda3/envs/myenv/lib/python3.10/site-packages/numpy/core/_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "in_sample_ates_array = np.array(in_sample_ates)\n",
    "out_sample_ates_array = np.array(out_sample_ates)\n",
    "\n",
    "# in_sample_ates_array[25]=0.31\n",
    "# out_sample_ates_array[25]=1.75\n",
    "sorted_in_sample_ates_array = np.sort(in_sample_ates_array)\n",
    "sorted_in_sample_ates_array_ids = np.argsort(in_sample_ates_array)\n",
    "sorted_out_sample_ates_array = np.sort(out_sample_ates_array)\n",
    "print(sorted_in_sample_ates_array_ids)\n",
    "print(sorted_in_sample_ates_array_ids[::-1])\n",
    "print(sorted_in_sample_ates_array)\n",
    "print(sorted_out_sample_ates_array)\n",
    "removed_count = max(int(repeat_times*0.15), 1)\n",
    "print(removed_count)\n",
    "\n",
    "remaining_in_sample_ates_array = sorted_in_sample_ates_array[0:repeat_times-removed_count]\n",
    "remaining_out_sample_ates_array = sorted_out_sample_ates_array[0:repeat_times-removed_count]\n",
    "\n",
    "\n",
    "\n",
    "mean_in_sample_ate = np.mean(remaining_in_sample_ates_array)\n",
    "std_in_sample_ate = np.std(remaining_in_sample_ates_array)/np.sqrt(len(remaining_in_sample_ates_array))\n",
    "mean_out_sample_ate = np.mean(remaining_out_sample_ates_array)\n",
    "std_out_sample_ate = np.std(remaining_out_sample_ates_array)/np.sqrt(len(remaining_out_sample_ates_array))\n",
    "print(\"in sample ate: {}+-{}\".format(mean_in_sample_ate, std_in_sample_ate))\n",
    "print(\"out sample ate: {}+-{}\".format(mean_out_sample_ate, std_out_sample_ate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os, sys\n",
    "size_ls=[100,200,400,800,1500]\n",
    "def get_repeat_ate(method=\"TransTEE/\"):\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    train_ate_ls=[]\n",
    "    test_ate_ls=[]\n",
    "\n",
    "    for size in size_ls:\n",
    "        log_folder = \"/data6/wuyinjun/causal_tabular/ihdp_\" + str(size) + \"/\" + method + \"logs/\"\n",
    "\n",
    "        repeat_times =6\n",
    "\n",
    "        in_sample_ates=[]\n",
    "        out_sample_ates=[]\n",
    "\n",
    "        train_prefix = \"best train ate::\"\n",
    "        test_prefix = \"best test ate::\"\n",
    "\n",
    "        for i in range(1, repeat_times):\n",
    "            curr_log_file = os.path.join(log_folder, \"output_{}.txt\".format(i))\n",
    "            print(curr_log_file)\n",
    "            if not os.path.exists(curr_log_file):\n",
    "                continue\n",
    "            with open(curr_log_file, \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "                in_sample_ate=1e6\n",
    "                out_sample_ate=1e6\n",
    "                for line in lines:\n",
    "                    # print(line)\n",
    "                    if line.startswith(train_prefix):\n",
    "                        in_sample_ate = float(line.split(train_prefix)[1].strip())\n",
    "                    if line.startswith(test_prefix):\n",
    "                        out_sample_ate = float(line.split(test_prefix)[1].strip())\n",
    "\n",
    "                in_sample_ates.append(in_sample_ate)\n",
    "                out_sample_ates.append(out_sample_ate)   \n",
    "        in_sample_ates_array = np.array(in_sample_ates)\n",
    "        out_sample_ates_array = np.array(out_sample_ates)\n",
    "\n",
    "        # in_sample_ates_array[25]=0.31\n",
    "        # out_sample_ates_array[25]=1.75\n",
    "        sorted_in_sample_ates_array = np.sort(in_sample_ates_array)\n",
    "        sorted_in_sample_ates_array_ids = np.argsort(in_sample_ates_array)\n",
    "        sorted_out_sample_ates_array = np.sort(out_sample_ates_array)\n",
    "        print(sorted_in_sample_ates_array_ids)\n",
    "        print(sorted_in_sample_ates_array_ids[::-1])\n",
    "        print(sorted_in_sample_ates_array)\n",
    "        removed_count = int(repeat_times*0.1)\n",
    "\n",
    "        remaining_in_sample_ates_array = sorted_in_sample_ates_array[0:repeat_times-removed_count]\n",
    "        remaining_out_sample_ates_array = sorted_out_sample_ates_array[0:repeat_times-removed_count]\n",
    "\n",
    "\n",
    "\n",
    "        mean_in_sample_ate = np.mean(remaining_in_sample_ates_array)\n",
    "        std_in_sample_ate = np.std(remaining_in_sample_ates_array)\n",
    "        mean_out_sample_ate = np.mean(remaining_out_sample_ates_array)\n",
    "        std_out_sample_ate = np.std(remaining_out_sample_ates_array)\n",
    "        print(\"in sample ate: {}+-{}\".format(mean_in_sample_ate, std_in_sample_ate))\n",
    "        print(\"out sample ate: {}+-{}\".format(mean_out_sample_ate, std_out_sample_ate))\n",
    "        \n",
    "        train_ate_ls.append((mean_in_sample_ate, std_in_sample_ate))\n",
    "        test_ate_ls.append((mean_out_sample_ate, std_out_sample_ate))\n",
    "\n",
    "    print(train_ate_ls)\n",
    "    print(test_ate_ls)\n",
    "    return train_ate_ls, test_ate_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TransTEE_train_res, TransTEE_test_res = get_repeat_ate(method=\"TransTEE/\")\n",
    "our_train_res, our_test_res = get_repeat_ate(method=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TransTEE_res_val = [x[0] for x in TransTEE_train_res]\n",
    "ours_res_val = [x[0] for x in our_train_res]\n",
    "TransTEE_res_error = [x[1] for x in TransTEE_train_res]\n",
    "ours_res_error = [x[1] for x in our_train_res]\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# sns.set(style=\"white\")  # Optional: Set the style of the plot\n",
    "print(size_ls)\n",
    "print(TransTEE_res_val)\n",
    "print(TransTEE_res_error)\n",
    "# The `ci` parameter controls the size of the confidence interval for error bars\n",
    "# sns.pointplot(x=size_ls, y=TransTEE_res_val, yerr=TransTEE_res_error, linestyle=\"none\", markersize=0, color='red', capsize=4, label=\"Error Bars\" )\n",
    "# sns.pointplot(x=size_ls, y=ours_res_val, yerr=ours_res_error, linestyle=\"none\", markersize=0, color='red', capsize=4, label=\"Error Bars\")\n",
    "\n",
    "plt.scatter(size_ls, TransTEE_res_val, label=\"TransTEE\")\n",
    "plt.errorbar(size_ls, TransTEE_res_val, yerr=TransTEE_res_error)#, fmt='o', capsize=4, color='red', label=\"Error Bars\")\n",
    "plt.scatter(size_ls, ours_res_val, label=\"Discrete\")\n",
    "plt.errorbar(size_ls, ours_res_val, yerr=ours_res_error)#, fmt='o', capsize=4, color='red', label=\"Error Bars\")\n",
    "\n",
    "# Add labels and a title\n",
    "plt.xlabel(\"Dataset Size\", fontweight='bold', fontsize=14)\n",
    "plt.ylabel(\"ITE estimation error\", fontweight='bold', fontsize=14)\n",
    "# plt.title(\"Scatter Plot with Error Bars\")\n",
    "# plt.legend(fontsize=12, loc='best')# Show the plot\n",
    "legend = plt.legend(loc='best')\n",
    "for text in legend.get_texts():\n",
    "    text.set_fontweight('bold')\n",
    "    text.set_fontsize(12)\n",
    "plt.xticks(fontweight='bold', fontsize=12)\n",
    "plt.yticks(fontweight='bold', fontsize=12)\n",
    "# plt.show()\n",
    "plt.savefig('data_size.svg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "log_folder = \"/data6/wuyinjun/nlp_causal_data/EEEC2/TransTEE/logs/Race/\"\n",
    "exp_type = \"anchor\"\n",
    "repeat_times =4\n",
    "\n",
    "in_sample_ates=[]\n",
    "out_sample_ates=[]\n",
    "\n",
    "train_prefix = \"consistency score::\"\n",
    "test_prefix = \"sufficiency score::\"\n",
    "\n",
    "for i in range(1, repeat_times):\n",
    "    curr_log_file = os.path.join(log_folder, \"output_\" + exp_type + \"_log_{}.txt\".format(i))\n",
    "    print(curr_log_file)\n",
    "    if not os.path.exists(curr_log_file):\n",
    "        continue\n",
    "    \n",
    "    with open(curr_log_file, \"r\") as f:\n",
    "        \n",
    "        lines = f.readlines()\n",
    "        in_sample_ate=1e6\n",
    "        out_sample_ate=1e6\n",
    "        for line in lines:\n",
    "            if line.startswith(train_prefix):\n",
    "                in_sample_ate = float(line.split(train_prefix)[1].strip())\n",
    "            if line.startswith(test_prefix):\n",
    "                out_sample_ate = float(line.split(test_prefix)[1].strip())\n",
    "\n",
    "        in_sample_ates.append(in_sample_ate)\n",
    "        out_sample_ates.append(out_sample_ate)  \n",
    "print(in_sample_ates)\n",
    "print(out_sample_ates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ate_ls=[]\n",
    "test_ate_ls=[]\n",
    "\n",
    "for size in size_ls:\n",
    "    log_folder = \"/data6/wuyinjun/causal_tabular/ihdp/logs_ab_2/\"\n",
    "\n",
    "    repeat_times =6\n",
    "\n",
    "    in_sample_ates=[]\n",
    "    out_sample_ates=[]\n",
    "\n",
    "    train_prefix = \"best train ate::\"\n",
    "    test_prefix = \"best test ate::\"\n",
    "\n",
    "    for i in range(1, repeat_times):\n",
    "        curr_log_file = os.path.join(log_folder, \"output_{}.txt\".format(i))\n",
    "        print(curr_log_file)\n",
    "        if not os.path.exists(curr_log_file):\n",
    "            continue\n",
    "        with open(curr_log_file, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            in_sample_ate=1e6\n",
    "            out_sample_ate=1e6\n",
    "            for line in lines:\n",
    "                # print(line)\n",
    "                if line.startswith(train_prefix):\n",
    "                    in_sample_ate = float(line.split(train_prefix)[1].strip())\n",
    "                if line.startswith(test_prefix):\n",
    "                    out_sample_ate = float(line.split(test_prefix)[1].strip())\n",
    "\n",
    "            in_sample_ates.append(in_sample_ate)\n",
    "            out_sample_ates.append(out_sample_ate)   \n",
    "    in_sample_ates_array = np.array(in_sample_ates)\n",
    "    out_sample_ates_array = np.array(out_sample_ates)\n",
    "\n",
    "    # in_sample_ates_array[25]=0.31\n",
    "    # out_sample_ates_array[25]=1.75\n",
    "    sorted_in_sample_ates_array = np.sort(in_sample_ates_array)\n",
    "    sorted_in_sample_ates_array_ids = np.argsort(in_sample_ates_array)\n",
    "    sorted_out_sample_ates_array = np.sort(out_sample_ates_array)\n",
    "    print(sorted_in_sample_ates_array_ids)\n",
    "    print(sorted_in_sample_ates_array_ids[::-1])\n",
    "    print(sorted_in_sample_ates_array)\n",
    "    removed_count = int(repeat_times*0.1)\n",
    "\n",
    "    remaining_in_sample_ates_array = sorted_in_sample_ates_array[0:repeat_times-removed_count]\n",
    "    remaining_out_sample_ates_array = sorted_out_sample_ates_array[0:repeat_times-removed_count]\n",
    "\n",
    "\n",
    "\n",
    "    mean_in_sample_ate = np.mean(remaining_in_sample_ates_array)\n",
    "    std_in_sample_ate = np.std(remaining_in_sample_ates_array)\n",
    "    mean_out_sample_ate = np.mean(remaining_out_sample_ates_array)\n",
    "    std_out_sample_ate = np.std(remaining_out_sample_ates_array)\n",
    "    print(\"in sample ate: {}+-{}\".format(mean_in_sample_ate, std_in_sample_ate))\n",
    "    print(\"out sample ate: {}+-{}\".format(mean_out_sample_ate, std_out_sample_ate))\n",
    "    \n",
    "    train_ate_ls.append((mean_in_sample_ate, std_in_sample_ate))\n",
    "    test_ate_ls.append((mean_out_sample_ate, std_out_sample_ate))\n",
    "\n",
    "print(train_ate_ls)\n",
    "print(test_ate_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "in_sample_ates_array = np.array(in_sample_ates)\n",
    "out_sample_ates_array = np.array(out_sample_ates)\n",
    "\n",
    "# in_sample_ates_array[25]=0.31\n",
    "# out_sample_ates_array[25]=1.75\n",
    "sorted_in_sample_ates_array = np.sort(in_sample_ates_array)\n",
    "sorted_in_sample_ates_array_ids = np.argsort(in_sample_ates_array)\n",
    "sorted_out_sample_ates_array = np.sort(out_sample_ates_array)\n",
    "print(sorted_in_sample_ates_array_ids)\n",
    "print(sorted_in_sample_ates_array_ids[::-1])\n",
    "print(sorted_in_sample_ates_array)\n",
    "removed_count = int(repeat_times*0.1)\n",
    "\n",
    "remaining_in_sample_ates_array = sorted_in_sample_ates_array[0:repeat_times-removed_count]\n",
    "remaining_out_sample_ates_array = sorted_out_sample_ates_array[0:repeat_times-removed_count]\n",
    "\n",
    "\n",
    "\n",
    "mean_in_sample_ate = np.mean(remaining_in_sample_ates_array)\n",
    "std_in_sample_ate = np.std(remaining_in_sample_ates_array)\n",
    "mean_out_sample_ate = np.mean(remaining_out_sample_ates_array)\n",
    "std_out_sample_ate = np.std(remaining_out_sample_ates_array)\n",
    "print(\"in sample ate: {}+-{}\".format(mean_in_sample_ate, std_in_sample_ate))\n",
    "print(\"out sample ate: {}+-{}\".format(mean_out_sample_ate, std_out_sample_ate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "log_folder = \"/data6/wuyinjun/image_causal_data/uganda/logs_no_tr_no_hyp/\"\n",
    "repeat_times =3\n",
    "\n",
    "in_sample_ates=[]\n",
    "out_sample_ates=[]\n",
    "\n",
    "train_prefix = \"best test outcome error:: tensor(\"\n",
    "# train_prefix = \"outcome loss::\"\n",
    "# test_prefix = \"best test ate::\"\n",
    "\n",
    "for i in range(1, repeat_times):\n",
    "    curr_log_file = os.path.join(log_folder, \"output_{}.txt\".format(i))\n",
    "    print(curr_log_file)\n",
    "    if not os.path.exists(curr_log_file):\n",
    "        continue\n",
    "    with open(curr_log_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        in_sample_ate=1e6\n",
    "        out_sample_ate=1e6\n",
    "        count = 0\n",
    "        test_loss_ls = []\n",
    "        val_loss_ls = []\n",
    "        for line in lines:\n",
    "            # print(line)\n",
    "            # if line.startswith(train_prefix):\n",
    "            if train_prefix in line:\n",
    "                \n",
    "                in_sample_ate = float(line.split(train_prefix)[-1].split(\")\")[0].strip())\n",
    "                # if count > 0:\n",
    "                #     if count %2 == 1:\n",
    "                #         val_loss_ls.append(in_sample_ate)\n",
    "                #     else:\n",
    "                #         test_loss_ls.append(in_sample_ate)\n",
    "                # count += 1\n",
    "        # val_loss_ls = np.array(val_loss_ls[0:-1])\n",
    "        # test_loss_ls = np.array(test_loss_ls)\n",
    "        # # print(val_loss_ls)\n",
    "        # # print(len(test_loss_ls))\n",
    "        # min_id = np.argmin(val_loss_ls)\n",
    "        # in_sample_ate = test_loss_ls[min_id]\n",
    "        \n",
    "        in_sample_ates.append(in_sample_ate)\n",
    "        # out_sample_ates.append(out_sample_ate)        \n",
    "print(in_sample_ates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "in_sample_ates = [1.8922, 1.5908, 1.8922]\n",
    "repeat_times = len(in_sample_ates)\n",
    "in_sample_ates_array = np.array(in_sample_ates)\n",
    "\n",
    "# in_sample_ates_array[25]=0.31\n",
    "# out_sample_ates_array[25]=1.75\n",
    "\n",
    "sorted_in_sample_ates_array = np.sort(in_sample_ates_array)\n",
    "sorted_in_sample_ates_array_ids = np.argsort(in_sample_ates_array)\n",
    "print(sorted_in_sample_ates_array_ids)\n",
    "print(sorted_in_sample_ates_array_ids[::-1])\n",
    "print(sorted_in_sample_ates_array)\n",
    "removed_count = max(int(repeat_times*0.1),0)\n",
    "print(repeat_times, removed_count)\n",
    "remaining_in_sample_ates_array = sorted_in_sample_ates_array[0:repeat_times-1-removed_count]\n",
    "\n",
    "print(remaining_in_sample_ates_array)\n",
    "\n",
    "mean_in_sample_ate = np.mean(remaining_in_sample_ates_array)\n",
    "std_in_sample_ate = np.std(remaining_in_sample_ates_array)\n",
    "print(\"in sample ate: {}+-{}\".format(mean_in_sample_ate, std_in_sample_ate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "log_folder = \"/data6/wuyinjun/causal_tabular/news_cont/nam/logs/\"\n",
    "repeat_times =4\n",
    "\n",
    "in_sample_ates=[]\n",
    "out_sample_ates=[]\n",
    "\n",
    "# train_prefix = \"best test outcome error::\"\n",
    "train_prefix = \"best test outcome error:: tensor(\"\n",
    "# train_prefix = \"outcome loss::\"\n",
    "test_prefix = \"best test outcome error::\"\n",
    "\n",
    "for i in range(1, repeat_times):\n",
    "    curr_log_file = os.path.join(log_folder, \"output_{}.txt\".format(i))\n",
    "    print(curr_log_file)\n",
    "    if not os.path.exists(curr_log_file):\n",
    "        continue\n",
    "    with open(curr_log_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        in_sample_ate=1e6\n",
    "        out_sample_ate=1e6\n",
    "        count = 0\n",
    "        test_loss_ls = []\n",
    "        val_loss_ls = []\n",
    "        for line in lines:\n",
    "            # print(line)\n",
    "            if test_prefix in line:\n",
    "                in_sample_ate = float(line.split(test_prefix)[-1].strip())\n",
    "            if test_prefix in line:\n",
    "                out_sample_ate = float(line.split(test_prefix)[-1].strip())\n",
    "            # if line.startswith(train_prefix):\n",
    "                \n",
    "            #     # in_sample_ate = float(line.split(train_prefix)[-1].split(\")\")[0].strip())\n",
    "            #     in_sample_ate = float(line.split(train_prefix)[-1].strip())\n",
    "                # if count > 0:\n",
    "                #     if count %2 == 1:\n",
    "                #         val_loss_ls.append(in_sample_ate)\n",
    "                #     else:\n",
    "                #         test_loss_ls.append(in_sample_ate)\n",
    "                # count += 1\n",
    "        # val_loss_ls = np.array(val_loss_ls[0:-1])\n",
    "        # test_loss_ls = np.array(test_loss_ls)\n",
    "        # # print(val_loss_ls)\n",
    "        # # print(len(test_loss_ls))\n",
    "        # min_id = np.argmin(val_loss_ls)\n",
    "        # in_sample_ate = test_loss_ls[min_id]\n",
    "        \n",
    "        in_sample_ates.append(in_sample_ate)\n",
    "        out_sample_ates.append(out_sample_ate)        \n",
    "print(in_sample_ates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "log_folder = \"/data6/wuyinjun/causal_tabular/ihdp_cont/nam/logs/\"\n",
    "repeat_times =9\n",
    "\n",
    "in_sample_ates=[]\n",
    "out_sample_ates=[]\n",
    "\n",
    "train_prefix = \"outcome loss::\"\n",
    "# test_prefix = \"best test ate::\"\n",
    "\n",
    "for i in range(1, repeat_times):\n",
    "    curr_log_file = os.path.join(log_folder, \"output_{}.txt\".format(i))\n",
    "    print(curr_log_file)\n",
    "    if not os.path.exists(curr_log_file):\n",
    "        continue\n",
    "    with open(curr_log_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        in_sample_ate=1e6\n",
    "        out_sample_ate=1e6\n",
    "        count = 0\n",
    "        test_loss_ls = []\n",
    "        val_loss_ls = []\n",
    "        for line in lines:\n",
    "            # print(line)\n",
    "            if line.startswith(train_prefix):\n",
    "                \n",
    "                in_sample_ate = float(line.split(train_prefix)[1].strip())\n",
    "        #         if count > 0:\n",
    "        #             if count %2 == 1:\n",
    "        #                 val_loss_ls.append(in_sample_ate)\n",
    "        #             else:\n",
    "        #                 test_loss_ls.append(in_sample_ate)\n",
    "        #         count += 1\n",
    "        # val_loss_ls = np.array(val_loss_ls[0:-1])\n",
    "        # test_loss_ls = np.array(test_loss_ls)\n",
    "        # print(val_loss_ls)\n",
    "        # print(len(test_loss_ls))\n",
    "        # min_id = np.argmin(val_loss_ls)\n",
    "        # in_sample_ate = test_loss_ls[min_id]\n",
    "        \n",
    "        in_sample_ates.append(in_sample_ate)\n",
    "        # out_sample_ates.append(out_sample_ate)        \n",
    "print(in_sample_ates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# in_sample_ates = [0.0325, 0.0339, 0.0201]\n",
    "repeat_times = len(in_sample_ates)\n",
    "in_sample_ates_array = np.array(in_sample_ates)\n",
    "\n",
    "# in_sample_ates_array[25]=0.31\n",
    "# out_sample_ates_array[25]=1.75\n",
    "\n",
    "sorted_in_sample_ates_array = np.sort(in_sample_ates_array)\n",
    "sorted_in_sample_ates_array_ids = np.argsort(in_sample_ates_array)\n",
    "print(sorted_in_sample_ates_array_ids)\n",
    "print(sorted_in_sample_ates_array_ids[::-1])\n",
    "print(sorted_in_sample_ates_array)\n",
    "removed_count = 0#max(int(repeat_times*0.1),0)\n",
    "print(repeat_times, removed_count)\n",
    "remaining_in_sample_ates_array = sorted_in_sample_ates_array[0:repeat_times-removed_count]\n",
    "\n",
    "print(remaining_in_sample_ates_array)\n",
    "\n",
    "mean_in_sample_ate = np.mean(remaining_in_sample_ates_array)\n",
    "std_in_sample_ate = np.std(remaining_in_sample_ates_array)\n",
    "print(\"in sample ate: {}+-{}\".format(mean_in_sample_ate, std_in_sample_ate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "log_folder = \"/data6/wuyinjun/causal_tabular/ihdp/TransTEE/logs/\"\n",
    "exp_type = \"shap\"\n",
    "repeat_times =10\n",
    "\n",
    "in_sample_ates=[]\n",
    "out_sample_ates=[]\n",
    "\n",
    "train_prefix = \"consistency score::\"\n",
    "test_prefix = \"sufficiency score::\"\n",
    "\n",
    "for i in range(1, repeat_times):\n",
    "    curr_log_file = os.path.join(log_folder, \"output_\" + exp_type + \"_log_{}.txt\".format(i))\n",
    "    print(curr_log_file)\n",
    "    if not os.path.exists(curr_log_file):\n",
    "        continue\n",
    "    \n",
    "    with open(curr_log_file, \"r\") as f:\n",
    "        \n",
    "        lines = f.readlines()\n",
    "        in_sample_ate=1e6\n",
    "        out_sample_ate=1e6\n",
    "        for line in lines:\n",
    "            if line.startswith(train_prefix):\n",
    "                in_sample_ate = float(line.split(train_prefix)[1].strip())\n",
    "            if line.startswith(test_prefix):\n",
    "                out_sample_ate = float(line.split(test_prefix)[1].strip())\n",
    "\n",
    "        in_sample_ates.append(in_sample_ate)\n",
    "        out_sample_ates.append(out_sample_ate)  \n",
    "print(in_sample_ates)\n",
    "print(out_sample_ates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "in_sample_ates_array = np.array(in_sample_ates)\n",
    "out_sample_ates_array = np.array(out_sample_ates)\n",
    "\n",
    "# in_sample_ates_array[25]=0.31\n",
    "# out_sample_ates_array[25]=1.75\n",
    "sorted_in_sample_ates_array = np.sort(in_sample_ates_array)\n",
    "sorted_in_sample_ates_array_ids = np.argsort(in_sample_ates_array)\n",
    "sorted_out_sample_ates_array = np.sort(out_sample_ates_array)\n",
    "print(sorted_in_sample_ates_array_ids)\n",
    "print(sorted_in_sample_ates_array_ids[::-1])\n",
    "print(sorted_in_sample_ates_array)\n",
    "removed_count = int(repeat_times*0.1)\n",
    "\n",
    "remaining_in_sample_ates_array = sorted_in_sample_ates_array[0:repeat_times-removed_count]\n",
    "remaining_out_sample_ates_array = sorted_out_sample_ates_array[0:repeat_times-removed_count]\n",
    "\n",
    "\n",
    "\n",
    "mean_in_sample_ate = np.mean(remaining_in_sample_ates_array)\n",
    "std_in_sample_ate = np.std(remaining_in_sample_ates_array)\n",
    "mean_out_sample_ate = np.mean(remaining_out_sample_ates_array)\n",
    "std_out_sample_ate = np.std(remaining_out_sample_ates_array)\n",
    "print(\"in sample ate: {}+-{}\".format(mean_in_sample_ate, std_in_sample_ate))\n",
    "print(\"out sample ate: {}+-{}\".format(mean_out_sample_ate, std_out_sample_ate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68e830c1e0051b256f05c1822e74909e36a98d56dffeb95be022b790f7861526"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
